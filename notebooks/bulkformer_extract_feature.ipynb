{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc45937",
   "metadata": {},
   "source": [
    "# BulkFormer Feature Extraction Tutorial\n",
    "\n",
    "This notebook demonstrates how to use **BulkFormer**, a graph-based attention Transformer model for extracting rich feature representations from bulk RNA-seq expression data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "BulkFormer integrates:\n",
    "1. **Gene co-expression networks** (GTEx-based gene-gene relationships)\n",
    "2. **Protein sequence embeddings** (ESM2 embeddings from protein sequences)\n",
    "3. **Expression values** (log-transformed TPM values)\n",
    "\n",
    "The model uses a Graph-Based Transformer architecture to learn contextualized gene embeddings that can be aggregated into sample-level representations for downstream tasks like drug response prediction, tissue classification, and disease phenotype analysis.\n",
    "\n",
    "**Reference:** [BulkFormer manuscript (bioRxiv 2025)](https://www.biorxiv.org/content/10.1101/2025.06.11.659222v1.full)\n",
    "\n",
    "## Package Structure\n",
    "\n",
    "This notebook uses the refactored `bulkformer` package:\n",
    "- **Model classes:** `bulkformer.models.model`\n",
    "- **Configuration:** `bulkformer.config`\n",
    "- **Utility functions:** `bulkformer.utils`\n",
    "\n",
    "For CLI usage: `uv run bulkformer extract --help`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d1b05",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, configure the GPU device to use. This is optional - the code will automatically fall back to CPU if CUDA is not available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a16039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b696803",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "Import all necessary packages:\n",
    "- **PyTorch & PyG:** For deep learning and graph operations\n",
    "- **BulkFormer components:** Model, configuration, and utility functions\n",
    "- **Data processing:** pandas, numpy for data manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2370d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch_geometric.typing import SparseTensor\n",
    "from bulkformer.models.model import BulkFormer\n",
    "from bulkformer.config import model_params\n",
    "from bulkformer.utils import normalize_data, align_genes, extract_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed50d95",
   "metadata": {},
   "source": [
    "## 3. Define Data Paths\n",
    "\n",
    "The notebook automatically detects the project root directory, handling execution from either:\n",
    "- The project root: `/path/to/BulkFormer/`\n",
    "- The notebooks folder: `/path/to/BulkFormer/notebooks/`\n",
    "\n",
    "All paths are resolved relative to the project root using `pathlib.Path`, ensuring the notebook works correctly regardless of the current working directory.\n",
    "\n",
    "Set paths to required data files:\n",
    "- **G_gtex.pt:** Gene co-expression graph structure (GTEx-based)\n",
    "- **G_gtex_weight.pt:** Edge weights for the gene graph\n",
    "- **esm2_feature_concat.pt:** Pre-computed ESM2 protein embeddings for all genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea2afcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Project root: /home/antonkulaga/sources/BulkFormer\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Detect project root (handle running from root or notebooks folder)\n",
    "current_dir: Path = Path.cwd()\n",
    "if current_dir.name == 'notebooks':\n",
    "    project_root: Path = current_dir.parent\n",
    "else:\n",
    "    project_root: Path = current_dir\n",
    "\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "\n",
    "# Configuration\n",
    "device: str = 'cuda'  # Use 'cpu' if CUDA is not available\n",
    "graph_path: Path = project_root / 'data' / 'G_gtex.pt'\n",
    "weights_path: Path = project_root / 'data' / 'G_gtex_weight.pt'\n",
    "gene_emb_path: Path = project_root / 'data' / 'esm2_feature_concat.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d3097",
   "metadata": {},
   "source": [
    "### 3.1 Download Required Files\n",
    "\n",
    "‚ö†Ô∏è **Note:** This notebook requires data and model files that need to be downloaded first.\n",
    "\n",
    "If you haven't downloaded them yet, run: `uv run bulkformer download all`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630bce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses data and model files from the data/ and model/ directories\n",
    "# If you get FileNotFoundError, download them with:\n",
    "#   cd {project_root}\n",
    "#   uv run bulkformer download all\n",
    "# \n",
    "# Or visit: https://doi.org/10.5281/zenodo.15559368\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dbf6fc",
   "metadata": {},
   "source": [
    "## 4. Initialize BulkFormer Model\n",
    "\n",
    "Load the model components and initialize BulkFormer:\n",
    "\n",
    "1. **Gene co-expression graph:** A sparse adjacency matrix representing gene-gene relationships learned from GTEx data\n",
    "2. **Graph weights:** Edge weights quantifying the strength of co-expression relationships\n",
    "3. **Gene embeddings:** ESM2-derived protein sequence embeddings (2560-dimensional per gene)\n",
    "\n",
    "The model uses these components to contextualize each gene's expression through graph-based attention mechanisms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5485ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BulkFormer model with preloaded graph structure and gene embeddings\n",
    "graph: torch.Tensor = torch.load(str(graph_path), map_location='cpu', weights_only=False)\n",
    "weights: torch.Tensor = torch.load(str(weights_path), map_location='cpu', weights_only=False)\n",
    "\n",
    "# Create sparse tensor representation for efficient graph operations\n",
    "graph: SparseTensor = SparseTensor(row=graph[1], col=graph[0], value=weights).t().to(device)\n",
    "\n",
    "# Load ESM2 protein embeddings (20,010 genes √ó 2560 dimensions)\n",
    "gene_emb: torch.Tensor = torch.load(str(gene_emb_path), map_location='cpu', weights_only=False)\n",
    "\n",
    "# Configure model with graph structure and embeddings\n",
    "model_params['graph'] = graph\n",
    "model_params['gene_emb'] = gene_emb\n",
    "\n",
    "# Initialize model and move to device\n",
    "model: BulkFormer = BulkFormer(**model_params).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d4420",
   "metadata": {},
   "source": [
    "## 5. Load Pre-trained Checkpoint\n",
    "\n",
    "Load the pre-trained BulkFormer weights (trained on GTEx + TCGA data).\n",
    "\n",
    "The model was trained with a reconstruction objective, learning to predict gene expression values while building contextualized gene representations through the graph-based attention layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bec646d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained BulkFormer model checkpoint\n",
    "model_checkpoint_path: Path = project_root / 'model' / 'Bulkformer_ckpt_epoch_29.pt'\n",
    "ckpt_model: dict = torch.load(str(model_checkpoint_path), weights_only=False)\n",
    "\n",
    "# Remove 'module.' prefix from keys (artifacts from DataParallel training)\n",
    "new_state_dict: OrderedDict = OrderedDict()\n",
    "for key, value in ckpt_model.items():\n",
    "    new_key: str = key[7:] if key.startswith(\"module.\") else key\n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "# Load weights into model\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff045f47",
   "metadata": {},
   "source": [
    "## 6. Utility Functions\n",
    "\n",
    "The following functions are imported from `bulkformer.utils`:\n",
    "\n",
    "### `normalize_data(X_df, gene_length_dict)`\n",
    "Converts raw RNA-seq counts to **log-transformed TPM** (Transcripts Per Million):\n",
    "- Normalizes for gene length (longer genes get more reads)\n",
    "- Normalizes for sequencing depth (total reads per sample)\n",
    "- Applies log1p transformation for variance stabilization\n",
    "\n",
    "### `align_genes(X_df, gene_list)`\n",
    "Aligns your expression data to BulkFormer's gene space (20,010 genes):\n",
    "- Adds missing genes with placeholder value (-10)\n",
    "- Reorders columns to match model's expected gene order\n",
    "- Returns a binary mask indicating which genes were imputed\n",
    "\n",
    "### `extract_features(model, expr_array, ...)`\n",
    "Extracts features from expression data:\n",
    "- **transcriptome_level:** Sample-level embeddings (aggregated across genes)\n",
    "- **gene_level:** Gene-level embeddings (per gene, per sample)\n",
    "- **expression_imputation:** Model-predicted expression values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c4560",
   "metadata": {},
   "source": [
    "## 7. Load Expression Data\n",
    "\n",
    "Load your bulk RNA-seq expression data. The demo file contains log-transformed TPM values for 968 samples.\n",
    "\n",
    "**Expected format:**\n",
    "- Rows: Samples\n",
    "- Columns: Genes (Ensembl IDs, e.g., ENSG00000000003)\n",
    "- Values: Log-transformed TPM (log(TPM + 1))\n",
    "\n",
    "If you have **raw counts** instead, see cells 10-11 for normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3718e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded expression data: 967 samples √ó 20009 genes\n"
     ]
    }
   ],
   "source": [
    "# Load demo normalized data (log-transformed TPM)\n",
    "demo_data_path: Path = project_root / 'data' / 'demo.csv'\n",
    "log_tpm_df: pd.DataFrame = pd.read_csv(demo_data_path, index_col=0)\n",
    "print(f\"Loaded expression data: {log_tpm_df.shape[0]} samples √ó {log_tpm_df.shape[1]} genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf6525",
   "metadata": {},
   "source": [
    "### 7.1 Optional: Normalization from Raw Counts\n",
    "\n",
    "If you have raw count data instead of normalized TPM, use the `normalize_data()` function:\n",
    "\n",
    "```python\n",
    "gene_length_path = project_root / 'data' / 'gene_length_df.csv'\n",
    "gene_length_df = pd.read_csv(gene_length_path)\n",
    "gene_length_dict = gene_length_df.set_index('ensg_id')['length'].to_dict()\n",
    "log_tpm_df = normalize_data(X_df=count_df, gene_length_dict=gene_length_dict)\n",
    "```\n",
    "\n",
    "This converts counts ‚Üí TPM ‚Üí log(TPM + 1) in one step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ede26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load raw count data if you have it\n",
    "# count_df = pd.read_csv('your_count_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Convert raw counts to normalized expression values (log-transformed TPM)\n",
    "# If you have raw count data, uncomment and run this cell\n",
    "# gene_length_path = project_root / 'data' / 'gene_length_df.csv'\n",
    "# gene_length_df = pd.read_csv(gene_length_path)\n",
    "# gene_length_dict = gene_length_df.set_index('ensg_id')['length'].to_dict()\n",
    "# log_tpm_df = normalize_data(X_df=count_df, gene_length_dict=gene_length_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ab7d1",
   "metadata": {},
   "source": [
    "## 8. Gene Alignment\n",
    "\n",
    "BulkFormer expects exactly **20,010 genes** in a specific order. The `align_genes()` function:\n",
    "1. Identifies missing genes in your data\n",
    "2. Adds them with placeholder value (-10)\n",
    "3. Reorders columns to match the model's expected gene order\n",
    "4. Creates a binary mask to track which genes were imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cbafdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BulkFormer expects 20010 genes\n"
     ]
    }
   ],
   "source": [
    "# Load BulkFormer's gene list (20,010 genes)\n",
    "gene_info_path: Path = project_root / 'data' / 'bulkformer_gene_info.csv'\n",
    "bulkformer_gene_info: pd.DataFrame = pd.read_csv(gene_info_path)\n",
    "bulkformer_gene_list: list[str] = bulkformer_gene_info['ensg_id'].to_list()\n",
    "print(f\"BulkFormer expects {len(bulkformer_gene_list)} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05327887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned data shape: (967, 20010)\n",
      "Number of genes imputed: 1\n"
     ]
    }
   ],
   "source": [
    "# Align expression data to BulkFormer's gene space\n",
    "input_df: pd.DataFrame\n",
    "to_fill_columns: list[str]\n",
    "var: pd.DataFrame\n",
    "input_df, to_fill_columns, var = align_genes(X_df=log_tpm_df, gene_list=bulkformer_gene_list)\n",
    "\n",
    "print(f\"Aligned data shape: {input_df.shape}\")\n",
    "print(f\"Number of genes imputed: {len(to_fill_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee387b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid (non-imputed) genes: 20009\n"
     ]
    }
   ],
   "source": [
    "var.reset_index(inplace=True)\n",
    "valid_gene_idx: list[int] = list(var[var['mask'] == 0].index)\n",
    "print(f\"Number of valid (non-imputed) genes: {len(valid_gene_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c4971",
   "metadata": {},
   "source": [
    "### 8.1 Identify Valid Genes\n",
    "\n",
    "Extract indices of genes that were **not** imputed (mask == 0). These are genes that were present in your original data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e934a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of high-variability genes: 2000\n"
     ]
    }
   ],
   "source": [
    "high_var_gene_path: Path = project_root / 'data' / 'high_var_gene_list.pt'\n",
    "high_var_gene_idx: torch.Tensor = torch.load(str(high_var_gene_path), weights_only=False)\n",
    "print(f\"Number of high-variability genes: {len(high_var_gene_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f140ef",
   "metadata": {},
   "source": [
    "### 8.2 Load High-Variability Genes\n",
    "\n",
    "Load indices of highly variable genes used for transcriptome-level aggregation. These genes were selected based on variance across GTEx training data and are most informative for sample-level representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ec8ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract transcriptome-level embedding (sample-level representation)\n",
    "# Using first 16 samples as example\n",
    "res1: torch.Tensor = extract_features(\n",
    "    model=model,\n",
    "    expr_array=input_df.values[:16],  # Shape: [n_samples, n_genes]\n",
    "    high_var_gene_idx=high_var_gene_idx,  # Highly variable genes for aggregation\n",
    "    feature_type='transcriptome_level',  # Aggregate to sample-level\n",
    "    aggregate_type='max',  # Use max pooling\n",
    "    device=device,\n",
    "    batch_size=4,\n",
    "    return_expr_value=False,  # Return embeddings, not expression predictions\n",
    "    esm2_emb=model_params['gene_emb'],\n",
    "    valid_gene_idx=valid_gene_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c4c2d9",
   "metadata": {},
   "source": [
    "## 9. Feature Extraction\n",
    "\n",
    "BulkFormer can extract three types of features:\n",
    "\n",
    "### 9.1 Transcriptome-Level Embeddings\n",
    "\n",
    "Sample-level representations created by aggregating gene embeddings from layer 2 of BulkFormer.\n",
    "\n",
    "**Aggregation methods:**\n",
    "- `'max'`: Maximum pooling across genes (captures peak signals)\n",
    "- `'mean'`: Average pooling (balanced representation)\n",
    "- `'median'`: Median pooling (robust to outliers)\n",
    "- `'all'`: Sum of max, mean, and median (most comprehensive)\n",
    "\n",
    "**Use cases:** Drug response prediction, tissue classification, disease phenotyping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a82275bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptome-level embeddings shape: torch.Size([16, 640])\n",
      "  - 16 samples\n",
      "  - 640 embedding dimensions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 640])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Transcriptome-level embeddings shape: {res1.shape}\")\n",
    "print(f\"  - {res1.shape[0]} samples\")\n",
    "print(f\"  - {res1.shape[1]} embedding dimensions\")\n",
    "res1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c20762",
   "metadata": {},
   "source": [
    "**Result shape:** `[n_samples, embedding_dim]`\n",
    "- Each sample is represented by a single vector\n",
    "- Default embedding dimension is 640 (from model config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e89a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4622, 0.3204, 0.8734,  ..., 2.5265, 2.0351, 2.1097],\n",
       "        [0.8776, 0.6784, 0.5454,  ..., 1.5435, 1.7944, 1.3206],\n",
       "        [2.0156, 1.1207, 1.0379,  ..., 2.4110, 2.2231, 2.2176],\n",
       "        ...,\n",
       "        [1.0094, 0.5021, 0.7578,  ..., 1.5157, 1.7562, 1.3782],\n",
       "        [1.1167, 0.8199, 0.5786,  ..., 1.7397, 1.8430, 1.0931],\n",
       "        [2.3170, 1.0496, 1.0248,  ..., 2.4119, 2.0700, 2.2761]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38e50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract gene-level embeddings (per-gene, per-sample)\n",
    "res2: torch.Tensor = extract_features(\n",
    "    model=model,\n",
    "    expr_array=input_df.values[:16],  # Shape: [n_samples, n_genes]\n",
    "    high_var_gene_idx=high_var_gene_idx,\n",
    "    feature_type='gene_level',  # Keep gene-level resolution\n",
    "    aggregate_type='all',  # Not used for gene_level, but required parameter\n",
    "    device=device,\n",
    "    batch_size=4,\n",
    "    return_expr_value=False,\n",
    "    esm2_emb=model_params['gene_emb'],  # Concatenate with ESM2 embeddings\n",
    "    valid_gene_idx=valid_gene_idx  # Only valid (non-imputed) genes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fcaa5c",
   "metadata": {},
   "source": [
    "### 9.2 Gene-Level Embeddings\n",
    "\n",
    "Per-gene, per-sample representations that concatenate:\n",
    "1. **BulkFormer embeddings** (context-aware, from layer 2)\n",
    "2. **ESM2 protein embeddings** (sequence-based, static)\n",
    "\n",
    "**Result:** Fused embeddings combining expression context and protein sequence information.\n",
    "\n",
    "**Use cases:** Gene-level predictions (e.g., essentiality, pathway activity), multi-modal learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d902a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene-level embeddings shape: torch.Size([16, 20009, 1920])\n",
      "  - 16 samples\n",
      "  - 20009 valid genes\n",
      "  - 1920 embedding dimensions (BulkFormer 640 + ESM2 2560)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20009, 1920])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Gene-level embeddings shape: {res2.shape}\")\n",
    "print(f\"  - {res2.shape[0]} samples\")\n",
    "print(f\"  - {res2.shape[1]} valid genes\")\n",
    "print(f\"  - {res2.shape[2]} embedding dimensions (BulkFormer 640 + ESM2 2560)\")\n",
    "res2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f188d",
   "metadata": {},
   "source": [
    "**Result shape:** `[n_samples, n_valid_genes, combined_dim]`\n",
    "- `combined_dim = bulkformer_dim (640) + esm2_dim (2560) = 3200`\n",
    "- Only non-imputed genes are included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "768fac44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0551, -1.8429,  0.1478,  ..., -0.0929, -0.0102,  0.0749],\n",
       "         [ 0.1574, -1.2592, -0.0561,  ..., -0.1507, -0.0174,  0.1455],\n",
       "         [ 1.0401,  0.0246,  0.6002,  ..., -0.0918,  0.0819,  0.0879],\n",
       "         ...,\n",
       "         [ 0.6453, -1.6589,  0.2273,  ..., -0.0316,  0.0078,  0.0943],\n",
       "         [ 1.1758, -1.7251,  0.3288,  ..., -0.0891, -0.0469,  0.1897],\n",
       "         [ 0.9684, -1.2767,  0.5495,  ..., -0.0528, -0.0946,  0.0670]],\n",
       "\n",
       "        [[ 0.2741, -1.6812, -0.1459,  ..., -0.0929, -0.0102,  0.0749],\n",
       "         [-1.3639, -1.1414, -0.2839,  ..., -0.1507, -0.0174,  0.1455],\n",
       "         [-0.4136, -2.3218, -0.5184,  ..., -0.0918,  0.0819,  0.0879],\n",
       "         ...,\n",
       "         [-0.3523, -1.3333, -0.3306,  ..., -0.0316,  0.0078,  0.0943],\n",
       "         [ 0.5097, -1.6272,  0.1369,  ..., -0.0891, -0.0469,  0.1897],\n",
       "         [ 0.5339, -1.0964,  0.0391,  ..., -0.0528, -0.0946,  0.0670]],\n",
       "\n",
       "        [[ 0.9490, -1.4407,  0.2156,  ..., -0.0929, -0.0102,  0.0749],\n",
       "         [-0.4132, -1.9796, -0.4000,  ..., -0.1507, -0.0174,  0.1455],\n",
       "         [ 0.2461, -2.5657, -0.4127,  ..., -0.0918,  0.0819,  0.0879],\n",
       "         ...,\n",
       "         [ 0.4730, -1.3009,  0.2295,  ..., -0.0316,  0.0078,  0.0943],\n",
       "         [ 1.0520, -1.4401,  0.4156,  ..., -0.0891, -0.0469,  0.1897],\n",
       "         [ 0.8655, -0.9335,  0.5342,  ..., -0.0528, -0.0946,  0.0670]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5252, -1.7779, -0.0660,  ..., -0.0929, -0.0102,  0.0749],\n",
       "         [-1.1901, -2.6777, -0.5123,  ..., -0.1507, -0.0174,  0.1455],\n",
       "         [-0.3663, -2.7736, -0.4308,  ..., -0.0918,  0.0819,  0.0879],\n",
       "         ...,\n",
       "         [-0.1216, -1.6576, -0.1642,  ..., -0.0316,  0.0078,  0.0943],\n",
       "         [ 0.5960, -1.8117,  0.1588,  ..., -0.0891, -0.0469,  0.1897],\n",
       "         [ 0.5693, -1.3024,  0.1442,  ..., -0.0528, -0.0946,  0.0670]],\n",
       "\n",
       "        [[ 0.1138, -3.0403, -0.8210,  ..., -0.0929, -0.0102,  0.0749],\n",
       "         [-1.2754, -1.2688, -0.4452,  ..., -0.1507, -0.0174,  0.1455],\n",
       "         [-0.4783, -2.5532, -0.7179,  ..., -0.0918,  0.0819,  0.0879],\n",
       "         ...,\n",
       "         [-0.3769, -1.5032, -0.3535,  ..., -0.0316,  0.0078,  0.0943],\n",
       "         [ 0.3576, -1.4038,  0.0760,  ..., -0.0891, -0.0469,  0.1897],\n",
       "         [ 0.4653, -1.0137, -0.0353,  ..., -0.0528, -0.0946,  0.0670]],\n",
       "\n",
       "        [[ 1.0360, -1.5218,  0.2694,  ..., -0.0929, -0.0102,  0.0749],\n",
       "         [ 0.1057, -0.0469,  0.4044,  ..., -0.1507, -0.0174,  0.1455],\n",
       "         [ 0.6250, -2.4815, -0.2737,  ..., -0.0918,  0.0819,  0.0879],\n",
       "         ...,\n",
       "         [ 0.6797, -1.2649,  0.3208,  ..., -0.0316,  0.0078,  0.0943],\n",
       "         [ 1.1300, -1.4702,  0.5010,  ..., -0.0891, -0.0469,  0.1897],\n",
       "         [ 0.9672, -0.9228,  0.6634,  ..., -0.0528, -0.0946,  0.0670]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3369f68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:06<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract model-predicted expression values (imputation)\n",
    "res3: np.ndarray = extract_features(\n",
    "    model=model,\n",
    "    expr_array=input_df.values[:16],  # Shape: [n_samples, n_genes]\n",
    "    high_var_gene_idx=high_var_gene_idx,\n",
    "    feature_type='transcriptome_level',\n",
    "    aggregate_type='all',\n",
    "    device=device,\n",
    "    batch_size=4,\n",
    "    return_expr_value=True,  # Return expression predictions instead of embeddings\n",
    "    esm2_emb=model_params['gene_emb'],\n",
    "    valid_gene_idx=valid_gene_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593c753",
   "metadata": {},
   "source": [
    "### 9.3 Expression Imputation\n",
    "\n",
    "Use BulkFormer's reconstruction head to predict/impute gene expression values.\n",
    "\n",
    "**Use cases:**\n",
    "- Impute missing genes in your data\n",
    "- Denoise expression measurements\n",
    "- Reconstruct full expression profiles from partial data\n",
    "\n",
    "**Note:** Set `return_expr_value=True` to get expression predictions instead of embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb76cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted expression values shape: (16, 20010)\n",
      "  - 16 samples\n",
      "  - 20010 genes (all 20,010 genes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 20010)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Predicted expression values shape: {res3.shape}\")\n",
    "print(f\"  - {res3.shape[0]} samples\")\n",
    "print(f\"  - {res3.shape[1]} genes (all 20,010 genes)\")\n",
    "res3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be8e3a",
   "metadata": {},
   "source": [
    "**Result shape:** `[n_samples, n_genes]`\n",
    "- Model's prediction of log-transformed TPM values\n",
    "- Can be compared with input to assess reconstruction quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c579789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2735547 , 0.17127015, 0.32037833, ..., 0.20279405, 0.19119827,\n",
       "        0.22872534],\n",
       "       [3.0849693 , 0.2441585 , 3.2666268 , ..., 3.9643104 , 0.2724411 ,\n",
       "        0.34996656],\n",
       "       [1.3099808 , 0.30123997, 0.7367003 , ..., 0.3702867 , 0.30796665,\n",
       "        0.3844244 ],\n",
       "       ...,\n",
       "       [0.9285814 , 0.20617509, 1.6781065 , ..., 0.24234761, 0.23101696,\n",
       "        0.29190505],\n",
       "       [4.0148835 , 1.7378029 , 3.1773732 , ..., 3.713794  , 0.44067258,\n",
       "        0.51471543],\n",
       "       [3.4331362 , 0.31305268, 4.104111  , ..., 0.33597103, 0.3229271 ,\n",
       "        0.37848967]], shape=(16, 20010), dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d5ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac22986b",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "You've successfully extracted three types of features from bulk RNA-seq data:\n",
    "\n",
    "1. **Transcriptome-level embeddings** (`res1`): Compact sample representations for downstream ML tasks\n",
    "2. **Gene-level embeddings** (`res2`): Rich per-gene features combining expression context and protein sequence\n",
    "3. **Expression predictions** (`res3`): Model-imputed gene expression values\n",
    "\n",
    "### Downstream Applications\n",
    "\n",
    "These features can be used for:\n",
    "- **Drug response prediction:** Train ML models using transcriptome embeddings\n",
    "- **Disease classification:** Use embeddings to classify cancer subtypes, disease stages, etc.\n",
    "- **Cross-dataset integration:** BulkFormer embeddings can bridge different RNA-seq datasets\n",
    "- **Gene function prediction:** Use gene-level embeddings for functional annotation\n",
    "- **Data imputation:** Use predicted expressions to fill missing values\n",
    "\n",
    "### Saving Results\n",
    "\n",
    "```python\n",
    "# Save embeddings (paths are relative to project root)\n",
    "output_dir = project_root / 'results'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "torch.save(res1, output_dir / 'transcriptome_embeddings.pt')\n",
    "torch.save(res2, output_dir / 'gene_level_embeddings.pt')\n",
    "\n",
    "# Save predictions as CSV\n",
    "pred_df = pd.DataFrame(res3, index=input_df.index[:16], columns=input_df.columns)\n",
    "pred_df.to_csv(output_dir / 'expression_predictions.csv')\n",
    "```\n",
    "\n",
    "### References\n",
    "\n",
    "- **BulkFormer paper:** [bioRxiv 2025.06.11.659222](https://www.biorxiv.org/content/10.1101/2025.06.11.659222v1.full)\n",
    "- **GTEx Consortium:** [https://gtexportal.org](https://gtexportal.org)\n",
    "- **ESM2 protein embeddings:** Lin et al., Science 2023\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
